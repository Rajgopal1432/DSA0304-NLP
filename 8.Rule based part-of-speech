import nltk
from nltk.tokenize import word_tokenize
nltk.download('punkt')
nltk.download('averaged_perceptron_tagger')



patterns = [
    (r'\b(?:Thelthe)\b', 'DET'),   
    (r'\b(?:cat|dog)\b', 'NOUN'),  
    (r'\b(?:islamlare)\b', 'VERB'), 
    (r'\b(?:quickly|brightly)\b', 'ADV'),  
    (r'\b(?:[A-Za-z]+)\b', 'NOUN')  
]


regexp_tagger = nltk.RegexpTagger(patterns)


sentences = [
    "The cat quickly runs.",
    "She is happy.",
    "The dog is running."
]


words = nltk.word_tokenize(sentences)
tagged_words = regexp_tagger.tag(words)
print(tagged_words)
